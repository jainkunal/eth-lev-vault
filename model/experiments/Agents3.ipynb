{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.16.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting keras\n",
      "  Downloading keras-3.3.3-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/kunaljain/opt/anaconda3/envs/gizaagents/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.5.4-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow)\n",
      "  Downloading h5py-3.11.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.3.2-cp311-cp311-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in /Users/kunaljain/opt/anaconda3/envs/gizaagents/lib/python3.11/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/kunaljain/opt/anaconda3/envs/gizaagents/lib/python3.11/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/kunaljain/opt/anaconda3/envs/gizaagents/lib/python3.11/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Users/kunaljain/opt/anaconda3/envs/gizaagents/lib/python3.11/site-packages (from tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/kunaljain/opt/anaconda3/envs/gizaagents/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/kunaljain/opt/anaconda3/envs/gizaagents/lib/python3.11/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/kunaljain/opt/anaconda3/envs/gizaagents/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.64.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.3 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/kunaljain/opt/anaconda3/envs/gizaagents/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: rich in /Users/kunaljain/opt/anaconda3/envs/gizaagents/lib/python3.11/site-packages (from keras) (13.7.1)\n",
      "Collecting namex (from keras)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras)\n",
      "  Downloading optree-0.11.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /Users/kunaljain/opt/anaconda3/envs/gizaagents/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kunaljain/opt/anaconda3/envs/gizaagents/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kunaljain/opt/anaconda3/envs/gizaagents/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kunaljain/opt/anaconda3/envs/gizaagents/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kunaljain/opt/anaconda3/envs/gizaagents/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/kunaljain/opt/anaconda3/envs/gizaagents/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Using cached werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/kunaljain/opt/anaconda3/envs/gizaagents/lib/python3.11/site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/kunaljain/opt/anaconda3/envs/gizaagents/lib/python3.11/site-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/kunaljain/opt/anaconda3/envs/gizaagents/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/kunaljain/opt/anaconda3/envs/gizaagents/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "Downloading tensorflow-2.16.1-cp311-cp311-macosx_12_0_arm64.whl (227.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.0/227.0 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.64.1-cp311-cp311-macosx_10_9_universal2.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.11.0-cp311-cp311-macosx_11_0_arm64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-macosx_11_0_arm64.whl (26.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.4/26.4 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.3.2-cp311-cp311-macosx_10_9_universal2.whl (389 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.8/389.8 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.0-cp311-cp311-macosx_12_0_arm64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.11.0-cp311-cp311-macosx_11_0_arm64.whl (274 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "Installing collected packages: namex, libclang, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, optree, opt-einsum, ml-dtypes, h5py, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 gast-0.5.4 google-pasta-0.2.0 grpcio-1.64.1 h5py-3.11.0 keras-3.3.3 libclang-18.1.1 ml-dtypes-0.3.2 namex-0.0.8 opt-einsum-3.3.0 optree-0.11.0 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-io-gcs-filesystem-0.37.0 termcolor-2.4.0 werkzeug-3.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install xgboost\n",
    "\n",
    "%pip install tensorflow keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Fetch ETH data\n",
    "eth_data = yf.download('ETH-USD', start='2020-01-01', end='2024-06-01')\n",
    "\n",
    "# Calculate EMA\n",
    "eth_data['EMA_12'] = eth_data['Close'].ewm(span=12, adjust=False).mean()\n",
    "eth_data['EMA_26'] = eth_data['Close'].ewm(span=26, adjust=False).mean()\n",
    "\n",
    "# Calculate MACD\n",
    "eth_data['MACD'] = eth_data['EMA_12'] - eth_data['EMA_26']\n",
    "eth_data['Signal_Line'] = eth_data['MACD'].ewm(span=9, adjust=False).mean()\n",
    "\n",
    "# Calculate RSI\n",
    "def calculate_rsi(data, window):\n",
    "    delta = data['Close'].diff(1)\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "eth_data['RSI'] = calculate_rsi(eth_data, 14)\n",
    "\n",
    "eth_data.dropna(inplace=True)\n",
    "eth_data.head()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Bollinger Bands\n",
    "eth_data['BB_Middle'] = eth_data['Close'].rolling(window=20).mean()\n",
    "eth_data['BB_Upper'] = eth_data['BB_Middle'] + (eth_data['Close'].rolling(window=20).std() * 2)\n",
    "eth_data['BB_Lower'] = eth_data['BB_Middle'] - (eth_data['Close'].rolling(window=20).std() * 2)\n",
    "\n",
    "# Stochastic Oscillator\n",
    "low_14 = eth_data['Low'].rolling(window=14).min()\n",
    "high_14 = eth_data['High'].rolling(window=14).max()\n",
    "eth_data['Stochastic'] = ((eth_data['Close'] - low_14) / (high_14 - low_14)) * 100\n",
    "\n",
    "# Average True Range (ATR)\n",
    "high_low = eth_data['High'] - eth_data['Low']\n",
    "high_close = np.abs(eth_data['High'] - eth_data['Close'].shift())\n",
    "low_close = np.abs(eth_data['Low'] - eth_data['Close'].shift())\n",
    "tr = high_low.combine(high_close, max).combine(low_close, max)\n",
    "eth_data['ATR'] = tr.rolling(window=14).mean()\n",
    "\n",
    "# On-Balance Volume (OBV)\n",
    "eth_data['OBV'] = (np.sign(eth_data['Close'].diff()) * eth_data['Volume']).fillna(0).cumsum()\n",
    "\n",
    "# MACD Histogram\n",
    "eth_data['MACD_Hist'] = eth_data['MACD'] - eth_data['Signal_Line']\n",
    "\n",
    "# Volume-weighted Average Price (VWAP)\n",
    "vwap = (eth_data['Volume'] * (eth_data['High'] + eth_data['Low'] + eth_data['Close']) / 3).cumsum() / eth_data['Volume'].cumsum()\n",
    "eth_data['VWAP'] = vwap\n",
    "\n",
    "eth_data.dropna(inplace=True)\n",
    "\n",
    "# Commodity Channel Index (CCI)\n",
    "def calculate_cci(data, ndays): \n",
    "    TP = (data['High'] + data['Low'] + data['Close']) / 3 \n",
    "    CCI = pd.Series((TP - TP.rolling(ndays).mean()) / (0.015 * TP.rolling(ndays).std()), name = 'CCI') \n",
    "    return CCI\n",
    "\n",
    "# Chaikin Money Flow (CMF)\n",
    "def calculate_cmf(data, ndays):\n",
    "    mfv = ((data['Close'] - data['Low']) - (data['High'] - data['Close'])) / (data['High'] - data['Low']) * data['Volume']\n",
    "    cmf = mfv.rolling(ndays).sum() / data['Volume'].rolling(ndays).sum()\n",
    "    return cmf\n",
    "\n",
    "# Money Flow Index (MFI)\n",
    "def calculate_mfi(data, window):\n",
    "    typical_price = (data['High'] + data['Low'] + data['Close']) / 3\n",
    "    raw_money_flow = typical_price * data['Volume']\n",
    "    positive_flow = raw_money_flow.copy()\n",
    "    negative_flow = raw_money_flow.copy()\n",
    "    positive_flow[data['Close'] <= data['Close'].shift(1)] = 0\n",
    "    negative_flow[data['Close'] > data['Close'].shift(1)] = 0\n",
    "    positive_mf = positive_flow.rolling(window).sum()\n",
    "    negative_mf = negative_flow.rolling(window).sum()\n",
    "    mfi = 100 - (100 / (1 + positive_mf / negative_mf))\n",
    "    return mfi\n",
    "\n",
    "# Additional features\n",
    "eth_data['RSI_7'] = calculate_rsi(eth_data, 7)\n",
    "eth_data['RSI_21'] = calculate_rsi(eth_data, 21)\n",
    "eth_data['Momentum'] = eth_data['Close'].diff(10)\n",
    "eth_data['ROC'] = eth_data['Close'].pct_change(periods=10) * 100\n",
    "eth_data['CCI'] = calculate_cci(eth_data, 20)\n",
    "eth_data['Williams_%R'] = ((high_14 - eth_data['Close']) / (high_14 - low_14)) * -100\n",
    "eth_data['CMF'] = calculate_cmf(eth_data, 20)\n",
    "eth_data['MFI'] = calculate_mfi(eth_data, 14)\n",
    "eth_data['Force_Index'] = eth_data['Close'].diff(1) * eth_data['Volume']\n",
    "\n",
    "eth_data.dropna(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ichimoku_cloud(data):\n",
    "    high_9 = data['High'].rolling(window=9).max()\n",
    "    low_9 = data['Low'].rolling(window=9).min()\n",
    "    high_26 = data['High'].rolling(window=26).max()\n",
    "    low_26 = data['Low'].rolling(window=26).min()\n",
    "    high_52 = data['High'].rolling(window=52).max()\n",
    "    low_52 = data['Low'].rolling(window=52).min()\n",
    "\n",
    "    data['Tenkan_Sen'] = (high_9 + low_9) / 2\n",
    "    data['Kijun_Sen'] = (high_26 + low_26) / 2\n",
    "    data['Senkou_Span_A'] = ((data['Tenkan_Sen'] + data['Kijun_Sen']) / 2).shift(26)\n",
    "    data['Senkou_Span_B'] = ((high_52 + low_52) / 2).shift(26)\n",
    "    data['Chikou_Span'] = data['Close'].shift(-26)\n",
    "    return data\n",
    "\n",
    "eth_data = ichimoku_cloud(eth_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rvi(data, period=14):\n",
    "    close_open = data['Close'] - data['Open']\n",
    "    high_low = data['High'] - data['Low']\n",
    "    \n",
    "    rvi = pd.Series((close_open.rolling(window=period).mean() / high_low.rolling(window=period).mean()), name='RVI')\n",
    "    data['RVI'] = rvi\n",
    "    return data\n",
    "\n",
    "eth_data = calculate_rvi(eth_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_keltner_channel(data, period=20):\n",
    "    typical_price = (data['High'] + data['Low'] + data['Close']) / 3\n",
    "    ema_tp = typical_price.ewm(span=period, adjust=False).mean()\n",
    "    atr = data['High'] - data['Low']\n",
    "    data['Keltner_Upper'] = ema_tp + (2 * atr)\n",
    "    data['Keltner_Lower'] = ema_tp - (2 * atr)\n",
    "    return data\n",
    "\n",
    "eth_data = calculate_keltner_channel(eth_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_donchian_channel(data, period=20):\n",
    "    data['Donchian_Upper'] = data['High'].rolling(window=period).max()\n",
    "    data['Donchian_Lower'] = data['Low'].rolling(window=period).min()\n",
    "    return data\n",
    "\n",
    "eth_data = calculate_donchian_channel(eth_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_force_index(data, period=13):\n",
    "    force_index = data['Close'].diff(period) * data['Volume']\n",
    "    data['Force_Index'] = force_index\n",
    "    return data\n",
    "\n",
    "eth_data = calculate_force_index(eth_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vortex(data, period=14):\n",
    "    tr = pd.Series(np.maximum((data['High'] - data['Low']), \n",
    "                              np.maximum(abs(data['High'] - data['Close'].shift(1)), \n",
    "                                         abs(data['Low'] - data['Close'].shift(1)))), name='TR')\n",
    "    vmp = abs(data['High'] - data['Low'].shift(1))\n",
    "    vmm = abs(data['Low'] - data['High'].shift(1))\n",
    "    \n",
    "    vip = vmp.rolling(window=period).sum() / tr.rolling(window=period).sum()\n",
    "    vim = vmm.rolling(window=period).sum() / tr.rolling(window=period).sum()\n",
    "    \n",
    "    data['Vortex_Positive'] = vip\n",
    "    data['Vortex_Negative'] = vim\n",
    "    return data\n",
    "\n",
    "eth_data = calculate_vortex(eth_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1561, 40)\n",
      "2020-02-22 00:00:00 2024-05-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(eth_data.shape)\n",
    "print(eth_data.index.min(), eth_data.index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Fetch S&P 500 data\n",
    "sp500_data = yf.download('^GSPC', start='2020-01-01', end='2024-06-01')\n",
    "\n",
    "# We are only interested in the closing prices\n",
    "sp500_data = sp500_data[['Close']].rename(columns={'Close': 'SP500_Close'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge S&P 500 data with ETH data on the same dates\n",
    "eth_sp500_data = eth_data[['Close']].rename(columns={'Close': 'ETH_Close'})\n",
    "merged_data = pd.merge(eth_sp500_data, sp500_data, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "# Calculate rolling correlations\n",
    "correlation_periods = [7, 14, 21, 28]\n",
    "for period in correlation_periods:\n",
    "    merged_data[f'Corr_{period}'] = merged_data['ETH_Close'].rolling(window=period).corr(merged_data['SP500_Close'])\n",
    "\n",
    "# Drop NaN values resulting from rolling calculations\n",
    "merged_data.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add correlation features to the original ETH data\n",
    "eth_data = eth_data.join(merged_data[[f'Corr_{period}' for period in correlation_periods]])\n",
    "eth_data.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1003, 44)\n",
      "2020-05-11 00:00:00 2024-05-03 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(eth_data.shape)\n",
    "print(eth_data.index.min(), eth_data.index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Define the indices to fetch\n",
    "indices = {\n",
    "    'DJIA': '^DJI',\n",
    "    'NASDAQ': '^IXIC',\n",
    "    # 'FTSE': '^FTSE',\n",
    "    # 'DAX': '^GDAXI',\n",
    "    # 'Nikkei': '^N225',\n",
    "    # 'Hang_Seng': '^HSI',\n",
    "    # 'Crude_Oil': 'CL=F',\n",
    "    'Gold': 'GC=F',\n",
    "    # 'Dollar_Index': 'DX-Y.NYB'\n",
    "}\n",
    "\n",
    "# Fetch data for each index\n",
    "index_data = {}\n",
    "for name, ticker in indices.items():\n",
    "    index_data[name] = yf.download(ticker, start='2020-01-01', end='2024-06-01')['Close'].rename(f'{name}_Close')\n",
    "    \n",
    "# Merge all index data into a single DataFrame\n",
    "index_data_df = pd.concat(index_data.values(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DJIA_Close</th>\n",
       "      <th>NASDAQ_Close</th>\n",
       "      <th>Gold_Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>28868.800781</td>\n",
       "      <td>9092.190430</td>\n",
       "      <td>1524.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>28634.880859</td>\n",
       "      <td>9020.769531</td>\n",
       "      <td>1549.199951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>28703.380859</td>\n",
       "      <td>9071.469727</td>\n",
       "      <td>1566.199951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>28583.679688</td>\n",
       "      <td>9068.580078</td>\n",
       "      <td>1571.800049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08</th>\n",
       "      <td>28745.089844</td>\n",
       "      <td>9129.240234</td>\n",
       "      <td>1557.400024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              DJIA_Close  NASDAQ_Close   Gold_Close\n",
       "Date                                               \n",
       "2020-01-02  28868.800781   9092.190430  1524.500000\n",
       "2020-01-03  28634.880859   9020.769531  1549.199951\n",
       "2020-01-06  28703.380859   9071.469727  1566.199951\n",
       "2020-01-07  28583.679688   9068.580078  1571.800049\n",
       "2020-01-08  28745.089844   9129.240234  1557.400024"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DJIA_Close      1\n",
       "NASDAQ_Close    1\n",
       "Gold_Close      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_data_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge ETH data with index data\n",
    "eth_index_data = eth_data[['Close']].rename(columns={'Close': 'ETH_Close'})\n",
    "merged_data = pd.merge(eth_index_data, index_data_df, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "# Calculate rolling correlations for each index\n",
    "correlation_periods = [7, 14, 21, 28]\n",
    "for name in indices.keys():\n",
    "    for period in correlation_periods:\n",
    "        merged_data[f'Corr_{name}_{period}'] = merged_data['ETH_Close'].rolling(window=period).corr(merged_data[f'{name}_Close'])\n",
    "\n",
    "# Drop NaN values resulting from rolling calculations\n",
    "# merged_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ETH_Close</th>\n",
       "      <th>DJIA_Close</th>\n",
       "      <th>NASDAQ_Close</th>\n",
       "      <th>Gold_Close</th>\n",
       "      <th>Corr_DJIA_7</th>\n",
       "      <th>Corr_DJIA_14</th>\n",
       "      <th>Corr_DJIA_21</th>\n",
       "      <th>Corr_DJIA_28</th>\n",
       "      <th>Corr_NASDAQ_7</th>\n",
       "      <th>Corr_NASDAQ_14</th>\n",
       "      <th>Corr_NASDAQ_21</th>\n",
       "      <th>Corr_NASDAQ_28</th>\n",
       "      <th>Corr_Gold_7</th>\n",
       "      <th>Corr_Gold_14</th>\n",
       "      <th>Corr_Gold_21</th>\n",
       "      <th>Corr_Gold_28</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-05-11</th>\n",
       "      <td>185.912842</td>\n",
       "      <td>24221.990234</td>\n",
       "      <td>9192.339844</td>\n",
       "      <td>1695.300049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-12</th>\n",
       "      <td>189.312500</td>\n",
       "      <td>23764.779297</td>\n",
       "      <td>9002.549805</td>\n",
       "      <td>1704.400024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-13</th>\n",
       "      <td>199.193283</td>\n",
       "      <td>23247.970703</td>\n",
       "      <td>8863.169922</td>\n",
       "      <td>1713.900024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-14</th>\n",
       "      <td>202.949097</td>\n",
       "      <td>23625.339844</td>\n",
       "      <td>8943.719727</td>\n",
       "      <td>1738.099976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-15</th>\n",
       "      <td>195.622665</td>\n",
       "      <td>23685.419922</td>\n",
       "      <td>9014.559570</td>\n",
       "      <td>1753.400024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ETH_Close    DJIA_Close  NASDAQ_Close   Gold_Close  Corr_DJIA_7  \\\n",
       "Date                                                                           \n",
       "2020-05-11  185.912842  24221.990234   9192.339844  1695.300049          NaN   \n",
       "2020-05-12  189.312500  23764.779297   9002.549805  1704.400024          NaN   \n",
       "2020-05-13  199.193283  23247.970703   8863.169922  1713.900024          NaN   \n",
       "2020-05-14  202.949097  23625.339844   8943.719727  1738.099976          NaN   \n",
       "2020-05-15  195.622665  23685.419922   9014.559570  1753.400024          NaN   \n",
       "\n",
       "            Corr_DJIA_14  Corr_DJIA_21  Corr_DJIA_28  Corr_NASDAQ_7  \\\n",
       "Date                                                                  \n",
       "2020-05-11           NaN           NaN           NaN            NaN   \n",
       "2020-05-12           NaN           NaN           NaN            NaN   \n",
       "2020-05-13           NaN           NaN           NaN            NaN   \n",
       "2020-05-14           NaN           NaN           NaN            NaN   \n",
       "2020-05-15           NaN           NaN           NaN            NaN   \n",
       "\n",
       "            Corr_NASDAQ_14  Corr_NASDAQ_21  Corr_NASDAQ_28  Corr_Gold_7  \\\n",
       "Date                                                                      \n",
       "2020-05-11             NaN             NaN             NaN          NaN   \n",
       "2020-05-12             NaN             NaN             NaN          NaN   \n",
       "2020-05-13             NaN             NaN             NaN          NaN   \n",
       "2020-05-14             NaN             NaN             NaN          NaN   \n",
       "2020-05-15             NaN             NaN             NaN          NaN   \n",
       "\n",
       "            Corr_Gold_14  Corr_Gold_21  Corr_Gold_28  \n",
       "Date                                                  \n",
       "2020-05-11           NaN           NaN           NaN  \n",
       "2020-05-12           NaN           NaN           NaN  \n",
       "2020-05-13           NaN           NaN           NaN  \n",
       "2020-05-14           NaN           NaN           NaN  \n",
       "2020-05-15           NaN           NaN           NaN  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ETH_Close          0\n",
       "DJIA_Close         0\n",
       "NASDAQ_Close       0\n",
       "Gold_Close         0\n",
       "Corr_DJIA_7        6\n",
       "Corr_DJIA_14      13\n",
       "Corr_DJIA_21      20\n",
       "Corr_DJIA_28      27\n",
       "Corr_NASDAQ_7      6\n",
       "Corr_NASDAQ_14    13\n",
       "Corr_NASDAQ_21    20\n",
       "Corr_NASDAQ_28    27\n",
       "Corr_Gold_7        6\n",
       "Corr_Gold_14      13\n",
       "Corr_Gold_21      20\n",
       "Corr_Gold_28      27\n",
       "dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ETH_Close          0\n",
       "DJIA_Close         0\n",
       "NASDAQ_Close       0\n",
       "Gold_Close         0\n",
       "Corr_DJIA_7        6\n",
       "Corr_DJIA_14      13\n",
       "Corr_DJIA_21      20\n",
       "Corr_DJIA_28      27\n",
       "Corr_NASDAQ_7      6\n",
       "Corr_NASDAQ_14    13\n",
       "Corr_NASDAQ_21    20\n",
       "Corr_NASDAQ_28    27\n",
       "Corr_Gold_7        6\n",
       "Corr_Gold_14      13\n",
       "Corr_Gold_21      20\n",
       "Corr_Gold_28      27\n",
       "dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1003, 16)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add correlation features to the original ETH data\n",
    "for name in indices.keys():\n",
    "    for period in correlation_periods:\n",
    "        eth_data[f'Corr_{name}_{period}'] = merged_data[f'Corr_{name}_{period}']\n",
    "\n",
    "eth_data.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>EMA_12</th>\n",
       "      <th>EMA_26</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal_Line</th>\n",
       "      <th>...</th>\n",
       "      <th>Corr_DJIA_21</th>\n",
       "      <th>Corr_DJIA_28</th>\n",
       "      <th>Corr_NASDAQ_7</th>\n",
       "      <th>Corr_NASDAQ_14</th>\n",
       "      <th>Corr_NASDAQ_21</th>\n",
       "      <th>Corr_NASDAQ_28</th>\n",
       "      <th>Corr_Gold_7</th>\n",
       "      <th>Corr_Gold_14</th>\n",
       "      <th>Corr_Gold_21</th>\n",
       "      <th>Corr_Gold_28</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-06-18</th>\n",
       "      <td>232.898697</td>\n",
       "      <td>234.570648</td>\n",
       "      <td>228.951431</td>\n",
       "      <td>232.101166</td>\n",
       "      <td>232.101166</td>\n",
       "      <td>6713800872</td>\n",
       "      <td>235.106484</td>\n",
       "      <td>230.643579</td>\n",
       "      <td>4.462905</td>\n",
       "      <td>7.029998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799682</td>\n",
       "      <td>0.871491</td>\n",
       "      <td>0.415533</td>\n",
       "      <td>0.122700</td>\n",
       "      <td>0.772530</td>\n",
       "      <td>0.855128</td>\n",
       "      <td>-0.616467</td>\n",
       "      <td>-0.400021</td>\n",
       "      <td>-0.242599</td>\n",
       "      <td>-0.136306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-19</th>\n",
       "      <td>231.954971</td>\n",
       "      <td>232.154114</td>\n",
       "      <td>226.795181</td>\n",
       "      <td>227.138290</td>\n",
       "      <td>227.138290</td>\n",
       "      <td>6946372590</td>\n",
       "      <td>233.880608</td>\n",
       "      <td>230.383928</td>\n",
       "      <td>3.496680</td>\n",
       "      <td>6.323334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.779910</td>\n",
       "      <td>0.877083</td>\n",
       "      <td>-0.339848</td>\n",
       "      <td>0.118800</td>\n",
       "      <td>0.714548</td>\n",
       "      <td>0.844781</td>\n",
       "      <td>-0.410506</td>\n",
       "      <td>-0.674338</td>\n",
       "      <td>-0.149855</td>\n",
       "      <td>-0.251909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-22</th>\n",
       "      <td>229.003372</td>\n",
       "      <td>243.776016</td>\n",
       "      <td>228.934738</td>\n",
       "      <td>242.533188</td>\n",
       "      <td>242.533188</td>\n",
       "      <td>9079586552</td>\n",
       "      <td>234.067714</td>\n",
       "      <td>231.117785</td>\n",
       "      <td>2.949929</td>\n",
       "      <td>4.566757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727426</td>\n",
       "      <td>0.865163</td>\n",
       "      <td>0.105267</td>\n",
       "      <td>0.170950</td>\n",
       "      <td>0.672941</td>\n",
       "      <td>0.833719</td>\n",
       "      <td>0.439227</td>\n",
       "      <td>-0.481528</td>\n",
       "      <td>-0.067796</td>\n",
       "      <td>-0.269292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-23</th>\n",
       "      <td>242.537018</td>\n",
       "      <td>244.864410</td>\n",
       "      <td>239.759735</td>\n",
       "      <td>244.142151</td>\n",
       "      <td>244.142151</td>\n",
       "      <td>6624530348</td>\n",
       "      <td>235.617627</td>\n",
       "      <td>232.082552</td>\n",
       "      <td>3.535075</td>\n",
       "      <td>4.360421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.660070</td>\n",
       "      <td>0.851612</td>\n",
       "      <td>0.769549</td>\n",
       "      <td>0.315898</td>\n",
       "      <td>0.630890</td>\n",
       "      <td>0.821780</td>\n",
       "      <td>0.750468</td>\n",
       "      <td>-0.211824</td>\n",
       "      <td>0.098633</td>\n",
       "      <td>-0.197483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-24</th>\n",
       "      <td>244.185928</td>\n",
       "      <td>248.508026</td>\n",
       "      <td>232.807739</td>\n",
       "      <td>235.772461</td>\n",
       "      <td>235.772461</td>\n",
       "      <td>8815030025</td>\n",
       "      <td>235.641448</td>\n",
       "      <td>232.355879</td>\n",
       "      <td>3.285569</td>\n",
       "      <td>4.145450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.587545</td>\n",
       "      <td>0.830252</td>\n",
       "      <td>0.787170</td>\n",
       "      <td>0.451944</td>\n",
       "      <td>0.541788</td>\n",
       "      <td>0.805858</td>\n",
       "      <td>0.642053</td>\n",
       "      <td>-0.214069</td>\n",
       "      <td>-0.020459</td>\n",
       "      <td>-0.132861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2020-06-18  232.898697  234.570648  228.951431  232.101166  232.101166   \n",
       "2020-06-19  231.954971  232.154114  226.795181  227.138290  227.138290   \n",
       "2020-06-22  229.003372  243.776016  228.934738  242.533188  242.533188   \n",
       "2020-06-23  242.537018  244.864410  239.759735  244.142151  244.142151   \n",
       "2020-06-24  244.185928  248.508026  232.807739  235.772461  235.772461   \n",
       "\n",
       "                Volume      EMA_12      EMA_26      MACD  Signal_Line  ...  \\\n",
       "Date                                                                   ...   \n",
       "2020-06-18  6713800872  235.106484  230.643579  4.462905     7.029998  ...   \n",
       "2020-06-19  6946372590  233.880608  230.383928  3.496680     6.323334  ...   \n",
       "2020-06-22  9079586552  234.067714  231.117785  2.949929     4.566757  ...   \n",
       "2020-06-23  6624530348  235.617627  232.082552  3.535075     4.360421  ...   \n",
       "2020-06-24  8815030025  235.641448  232.355879  3.285569     4.145450  ...   \n",
       "\n",
       "            Corr_DJIA_21  Corr_DJIA_28  Corr_NASDAQ_7  Corr_NASDAQ_14  \\\n",
       "Date                                                                    \n",
       "2020-06-18      0.799682      0.871491       0.415533        0.122700   \n",
       "2020-06-19      0.779910      0.877083      -0.339848        0.118800   \n",
       "2020-06-22      0.727426      0.865163       0.105267        0.170950   \n",
       "2020-06-23      0.660070      0.851612       0.769549        0.315898   \n",
       "2020-06-24      0.587545      0.830252       0.787170        0.451944   \n",
       "\n",
       "            Corr_NASDAQ_21  Corr_NASDAQ_28  Corr_Gold_7  Corr_Gold_14  \\\n",
       "Date                                                                    \n",
       "2020-06-18        0.772530        0.855128    -0.616467     -0.400021   \n",
       "2020-06-19        0.714548        0.844781    -0.410506     -0.674338   \n",
       "2020-06-22        0.672941        0.833719     0.439227     -0.481528   \n",
       "2020-06-23        0.630890        0.821780     0.750468     -0.211824   \n",
       "2020-06-24        0.541788        0.805858     0.642053     -0.214069   \n",
       "\n",
       "            Corr_Gold_21  Corr_Gold_28  \n",
       "Date                                    \n",
       "2020-06-18     -0.242599     -0.136306  \n",
       "2020-06-19     -0.149855     -0.251909  \n",
       "2020-06-22     -0.067796     -0.269292  \n",
       "2020-06-23      0.098633     -0.197483  \n",
       "2020-06-24     -0.020459     -0.132861  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eth_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(976, 56)\n",
      "(976, 56)\n"
     ]
    }
   ],
   "source": [
    "print(eth_data.shape)\n",
    "eth_data.dropna(inplace=True)\n",
    "print(eth_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>EMA_12</th>\n",
       "      <th>EMA_26</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal_Line</th>\n",
       "      <th>...</th>\n",
       "      <th>Corr_DJIA_21</th>\n",
       "      <th>Corr_DJIA_28</th>\n",
       "      <th>Corr_NASDAQ_7</th>\n",
       "      <th>Corr_NASDAQ_14</th>\n",
       "      <th>Corr_NASDAQ_21</th>\n",
       "      <th>Corr_NASDAQ_28</th>\n",
       "      <th>Corr_Gold_7</th>\n",
       "      <th>Corr_Gold_14</th>\n",
       "      <th>Corr_Gold_21</th>\n",
       "      <th>Corr_Gold_28</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-06-18</th>\n",
       "      <td>232.898697</td>\n",
       "      <td>234.570648</td>\n",
       "      <td>228.951431</td>\n",
       "      <td>232.101166</td>\n",
       "      <td>232.101166</td>\n",
       "      <td>6713800872</td>\n",
       "      <td>235.106484</td>\n",
       "      <td>230.643579</td>\n",
       "      <td>4.462905</td>\n",
       "      <td>7.029998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799682</td>\n",
       "      <td>0.871491</td>\n",
       "      <td>0.415533</td>\n",
       "      <td>0.122700</td>\n",
       "      <td>0.772530</td>\n",
       "      <td>0.855128</td>\n",
       "      <td>-0.616467</td>\n",
       "      <td>-0.400021</td>\n",
       "      <td>-0.242599</td>\n",
       "      <td>-0.136306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-19</th>\n",
       "      <td>231.954971</td>\n",
       "      <td>232.154114</td>\n",
       "      <td>226.795181</td>\n",
       "      <td>227.138290</td>\n",
       "      <td>227.138290</td>\n",
       "      <td>6946372590</td>\n",
       "      <td>233.880608</td>\n",
       "      <td>230.383928</td>\n",
       "      <td>3.496680</td>\n",
       "      <td>6.323334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.779910</td>\n",
       "      <td>0.877083</td>\n",
       "      <td>-0.339848</td>\n",
       "      <td>0.118800</td>\n",
       "      <td>0.714548</td>\n",
       "      <td>0.844781</td>\n",
       "      <td>-0.410506</td>\n",
       "      <td>-0.674338</td>\n",
       "      <td>-0.149855</td>\n",
       "      <td>-0.251909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-22</th>\n",
       "      <td>229.003372</td>\n",
       "      <td>243.776016</td>\n",
       "      <td>228.934738</td>\n",
       "      <td>242.533188</td>\n",
       "      <td>242.533188</td>\n",
       "      <td>9079586552</td>\n",
       "      <td>234.067714</td>\n",
       "      <td>231.117785</td>\n",
       "      <td>2.949929</td>\n",
       "      <td>4.566757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727426</td>\n",
       "      <td>0.865163</td>\n",
       "      <td>0.105267</td>\n",
       "      <td>0.170950</td>\n",
       "      <td>0.672941</td>\n",
       "      <td>0.833719</td>\n",
       "      <td>0.439227</td>\n",
       "      <td>-0.481528</td>\n",
       "      <td>-0.067796</td>\n",
       "      <td>-0.269292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-23</th>\n",
       "      <td>242.537018</td>\n",
       "      <td>244.864410</td>\n",
       "      <td>239.759735</td>\n",
       "      <td>244.142151</td>\n",
       "      <td>244.142151</td>\n",
       "      <td>6624530348</td>\n",
       "      <td>235.617627</td>\n",
       "      <td>232.082552</td>\n",
       "      <td>3.535075</td>\n",
       "      <td>4.360421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.660070</td>\n",
       "      <td>0.851612</td>\n",
       "      <td>0.769549</td>\n",
       "      <td>0.315898</td>\n",
       "      <td>0.630890</td>\n",
       "      <td>0.821780</td>\n",
       "      <td>0.750468</td>\n",
       "      <td>-0.211824</td>\n",
       "      <td>0.098633</td>\n",
       "      <td>-0.197483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-24</th>\n",
       "      <td>244.185928</td>\n",
       "      <td>248.508026</td>\n",
       "      <td>232.807739</td>\n",
       "      <td>235.772461</td>\n",
       "      <td>235.772461</td>\n",
       "      <td>8815030025</td>\n",
       "      <td>235.641448</td>\n",
       "      <td>232.355879</td>\n",
       "      <td>3.285569</td>\n",
       "      <td>4.145450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.587545</td>\n",
       "      <td>0.830252</td>\n",
       "      <td>0.787170</td>\n",
       "      <td>0.451944</td>\n",
       "      <td>0.541788</td>\n",
       "      <td>0.805858</td>\n",
       "      <td>0.642053</td>\n",
       "      <td>-0.214069</td>\n",
       "      <td>-0.020459</td>\n",
       "      <td>-0.132861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-29</th>\n",
       "      <td>3262.340820</td>\n",
       "      <td>3285.468750</td>\n",
       "      <td>3116.199951</td>\n",
       "      <td>3215.428955</td>\n",
       "      <td>3215.428955</td>\n",
       "      <td>15032246816</td>\n",
       "      <td>3196.545648</td>\n",
       "      <td>3240.960923</td>\n",
       "      <td>-44.415275</td>\n",
       "      <td>-66.236104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.709003</td>\n",
       "      <td>0.772927</td>\n",
       "      <td>0.474255</td>\n",
       "      <td>0.712441</td>\n",
       "      <td>0.764125</td>\n",
       "      <td>0.808132</td>\n",
       "      <td>-0.689733</td>\n",
       "      <td>-0.459548</td>\n",
       "      <td>-0.477669</td>\n",
       "      <td>-0.640666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-30</th>\n",
       "      <td>3215.381104</td>\n",
       "      <td>3249.378418</td>\n",
       "      <td>2918.228760</td>\n",
       "      <td>3012.286865</td>\n",
       "      <td>3012.286865</td>\n",
       "      <td>18266894653</td>\n",
       "      <td>3168.198143</td>\n",
       "      <td>3224.022104</td>\n",
       "      <td>-55.823961</td>\n",
       "      <td>-64.153675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704735</td>\n",
       "      <td>0.779383</td>\n",
       "      <td>0.069502</td>\n",
       "      <td>0.692764</td>\n",
       "      <td>0.752990</td>\n",
       "      <td>0.812635</td>\n",
       "      <td>0.866043</td>\n",
       "      <td>-0.123491</td>\n",
       "      <td>-0.280332</td>\n",
       "      <td>-0.593374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-01</th>\n",
       "      <td>3011.015625</td>\n",
       "      <td>3020.173340</td>\n",
       "      <td>2815.923340</td>\n",
       "      <td>2969.784668</td>\n",
       "      <td>2969.784668</td>\n",
       "      <td>20005057445</td>\n",
       "      <td>3137.672993</td>\n",
       "      <td>3205.189701</td>\n",
       "      <td>-67.516708</td>\n",
       "      <td>-64.826282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.764990</td>\n",
       "      <td>0.785961</td>\n",
       "      <td>0.511074</td>\n",
       "      <td>0.413389</td>\n",
       "      <td>0.775077</td>\n",
       "      <td>0.817704</td>\n",
       "      <td>0.890584</td>\n",
       "      <td>-0.015702</td>\n",
       "      <td>-0.189027</td>\n",
       "      <td>-0.545821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-02</th>\n",
       "      <td>2969.794434</td>\n",
       "      <td>3015.050293</td>\n",
       "      <td>2894.329834</td>\n",
       "      <td>2988.168457</td>\n",
       "      <td>2988.168457</td>\n",
       "      <td>13163903903</td>\n",
       "      <td>3114.672295</td>\n",
       "      <td>3189.114053</td>\n",
       "      <td>-74.441758</td>\n",
       "      <td>-66.749377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786732</td>\n",
       "      <td>0.798992</td>\n",
       "      <td>0.460204</td>\n",
       "      <td>0.138136</td>\n",
       "      <td>0.763070</td>\n",
       "      <td>0.823772</td>\n",
       "      <td>0.950126</td>\n",
       "      <td>0.077838</td>\n",
       "      <td>-0.079934</td>\n",
       "      <td>-0.554518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-03</th>\n",
       "      <td>2988.134521</td>\n",
       "      <td>3127.155273</td>\n",
       "      <td>2960.182129</td>\n",
       "      <td>3103.541992</td>\n",
       "      <td>3103.541992</td>\n",
       "      <td>12862183229</td>\n",
       "      <td>3112.959941</td>\n",
       "      <td>3182.775382</td>\n",
       "      <td>-69.815441</td>\n",
       "      <td>-67.362590</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725308</td>\n",
       "      <td>0.768719</td>\n",
       "      <td>0.440199</td>\n",
       "      <td>0.129293</td>\n",
       "      <td>0.716894</td>\n",
       "      <td>0.785589</td>\n",
       "      <td>0.871120</td>\n",
       "      <td>0.062583</td>\n",
       "      <td>0.002707</td>\n",
       "      <td>-0.487636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>976 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close    Adj Close  \\\n",
       "Date                                                                          \n",
       "2020-06-18   232.898697   234.570648   228.951431   232.101166   232.101166   \n",
       "2020-06-19   231.954971   232.154114   226.795181   227.138290   227.138290   \n",
       "2020-06-22   229.003372   243.776016   228.934738   242.533188   242.533188   \n",
       "2020-06-23   242.537018   244.864410   239.759735   244.142151   244.142151   \n",
       "2020-06-24   244.185928   248.508026   232.807739   235.772461   235.772461   \n",
       "...                 ...          ...          ...          ...          ...   \n",
       "2024-04-29  3262.340820  3285.468750  3116.199951  3215.428955  3215.428955   \n",
       "2024-04-30  3215.381104  3249.378418  2918.228760  3012.286865  3012.286865   \n",
       "2024-05-01  3011.015625  3020.173340  2815.923340  2969.784668  2969.784668   \n",
       "2024-05-02  2969.794434  3015.050293  2894.329834  2988.168457  2988.168457   \n",
       "2024-05-03  2988.134521  3127.155273  2960.182129  3103.541992  3103.541992   \n",
       "\n",
       "                 Volume       EMA_12       EMA_26       MACD  Signal_Line  \\\n",
       "Date                                                                        \n",
       "2020-06-18   6713800872   235.106484   230.643579   4.462905     7.029998   \n",
       "2020-06-19   6946372590   233.880608   230.383928   3.496680     6.323334   \n",
       "2020-06-22   9079586552   234.067714   231.117785   2.949929     4.566757   \n",
       "2020-06-23   6624530348   235.617627   232.082552   3.535075     4.360421   \n",
       "2020-06-24   8815030025   235.641448   232.355879   3.285569     4.145450   \n",
       "...                 ...          ...          ...        ...          ...   \n",
       "2024-04-29  15032246816  3196.545648  3240.960923 -44.415275   -66.236104   \n",
       "2024-04-30  18266894653  3168.198143  3224.022104 -55.823961   -64.153675   \n",
       "2024-05-01  20005057445  3137.672993  3205.189701 -67.516708   -64.826282   \n",
       "2024-05-02  13163903903  3114.672295  3189.114053 -74.441758   -66.749377   \n",
       "2024-05-03  12862183229  3112.959941  3182.775382 -69.815441   -67.362590   \n",
       "\n",
       "            ...  Corr_DJIA_21  Corr_DJIA_28  Corr_NASDAQ_7  Corr_NASDAQ_14  \\\n",
       "Date        ...                                                              \n",
       "2020-06-18  ...      0.799682      0.871491       0.415533        0.122700   \n",
       "2020-06-19  ...      0.779910      0.877083      -0.339848        0.118800   \n",
       "2020-06-22  ...      0.727426      0.865163       0.105267        0.170950   \n",
       "2020-06-23  ...      0.660070      0.851612       0.769549        0.315898   \n",
       "2020-06-24  ...      0.587545      0.830252       0.787170        0.451944   \n",
       "...         ...           ...           ...            ...             ...   \n",
       "2024-04-29  ...      0.709003      0.772927       0.474255        0.712441   \n",
       "2024-04-30  ...      0.704735      0.779383       0.069502        0.692764   \n",
       "2024-05-01  ...      0.764990      0.785961       0.511074        0.413389   \n",
       "2024-05-02  ...      0.786732      0.798992       0.460204        0.138136   \n",
       "2024-05-03  ...      0.725308      0.768719       0.440199        0.129293   \n",
       "\n",
       "            Corr_NASDAQ_21  Corr_NASDAQ_28  Corr_Gold_7  Corr_Gold_14  \\\n",
       "Date                                                                    \n",
       "2020-06-18        0.772530        0.855128    -0.616467     -0.400021   \n",
       "2020-06-19        0.714548        0.844781    -0.410506     -0.674338   \n",
       "2020-06-22        0.672941        0.833719     0.439227     -0.481528   \n",
       "2020-06-23        0.630890        0.821780     0.750468     -0.211824   \n",
       "2020-06-24        0.541788        0.805858     0.642053     -0.214069   \n",
       "...                    ...             ...          ...           ...   \n",
       "2024-04-29        0.764125        0.808132    -0.689733     -0.459548   \n",
       "2024-04-30        0.752990        0.812635     0.866043     -0.123491   \n",
       "2024-05-01        0.775077        0.817704     0.890584     -0.015702   \n",
       "2024-05-02        0.763070        0.823772     0.950126      0.077838   \n",
       "2024-05-03        0.716894        0.785589     0.871120      0.062583   \n",
       "\n",
       "            Corr_Gold_21  Corr_Gold_28  \n",
       "Date                                    \n",
       "2020-06-18     -0.242599     -0.136306  \n",
       "2020-06-19     -0.149855     -0.251909  \n",
       "2020-06-22     -0.067796     -0.269292  \n",
       "2020-06-23      0.098633     -0.197483  \n",
       "2020-06-24     -0.020459     -0.132861  \n",
       "...                  ...           ...  \n",
       "2024-04-29     -0.477669     -0.640666  \n",
       "2024-04-30     -0.280332     -0.593374  \n",
       "2024-05-01     -0.189027     -0.545821  \n",
       "2024-05-02     -0.079934     -0.554518  \n",
       "2024-05-03      0.002707     -0.487636  \n",
       "\n",
       "[976 rows x 56 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eth_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6153846153846154\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.56      0.57        88\n",
      "           1       0.65      0.66      0.65       107\n",
      "\n",
      "    accuracy                           0.62       195\n",
      "   macro avg       0.61      0.61      0.61       195\n",
      "weighted avg       0.61      0.62      0.61       195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create target variable (1 if next day's close price is higher, else 0)\n",
    "eth_data['Target'] = (eth_data['Close'].shift(-1) > eth_data['Close']).astype(int)\n",
    "\n",
    "# Features including the new ones\n",
    "features = [\n",
    "    'Open', 'High', 'Low', 'Close', 'Volume',\n",
    "    'MACD', 'Signal_Line', 'RSI',\n",
    "    'BB_Middle', 'BB_Upper', 'BB_Lower',\n",
    "    'Stochastic', 'ATR', 'OBV', 'MACD_Hist', 'VWAP',\n",
    "    'RSI_7', 'RSI_21', 'Momentum', 'ROC', 'CCI', 'Williams_%R', 'CMF', 'MFI', 'Force_Index',\n",
    "    'Tenkan_Sen', 'Kijun_Sen', 'Senkou_Span_A', 'Senkou_Span_B', 'Chikou_Span', 'RVI',\n",
    "    'Keltner_Upper', 'Keltner_Lower', 'Donchian_Upper', 'Donchian_Lower',\n",
    "    'Vortex_Positive', 'Vortex_Negative',\n",
    "    'Corr_7', 'Corr_14', 'Corr_21', 'Corr_28'\n",
    "] + [f'Corr_{name}_{period}' for name in indices.keys() for period in correlation_periods]\n",
    "\n",
    "X = eth_data[features]\n",
    "y = eth_data['Target']\n",
    "\n",
    "# Drop the last row as it will have NaN target value\n",
    "X = X[:-1]\n",
    "y = y[:-1]\n",
    "\n",
    "# Polynomial Features\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "poly_features = poly.fit_transform(X)\n",
    "poly_feature_names = poly.get_feature_names_out(X.columns)\n",
    "\n",
    "# Create a DataFrame with the new features\n",
    "poly_df = pd.DataFrame(poly_features, columns=poly_feature_names, index=X.index)\n",
    "\n",
    "# Combine with the original features\n",
    "X_poly = pd.concat([X, poly_df], axis=1)\n",
    "\n",
    "# Recursive Feature Elimination\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# rfe = RFE(estimator=rf, n_features_to_select=20)\n",
    "# X_rfe = rfe.fit_transform(X_poly, y)\n",
    "# selected_features = X_poly.columns[rfe.support_]\n",
    "\n",
    "selected_features = ['OBV VWAP', 'VWAP Keltner_Lower', 'RSI_7 Vortex_Negative',\n",
    "       'Williams_%R RVI', 'Williams_%R Corr_DJIA_21', 'CMF Corr_Gold_14',\n",
    "       'Vortex_Positive Vortex_Negative', 'Corr_DJIA_7 Corr_Gold_7',\n",
    "       'Corr_DJIA_7 Corr_Gold_14', 'Corr_DJIA_21 Corr_DJIA_28']\n",
    "\n",
    "# selected_features = ['Stochastic Vortex_Negative', 'OBV VWAP', 'MACD_Hist ROC',\n",
    "#        'VWAP Keltner_Lower', 'VWAP Vortex_Negative', 'RSI_7 Vortex_Negative',\n",
    "#        'RSI_21 Vortex_Negative', 'CCI RVI', 'Williams_%R Kijun_Sen',\n",
    "#        'Williams_%R RVI', 'Williams_%R Corr_DJIA_21', 'CMF Corr_Gold_14',\n",
    "#        'Vortex_Positive Vortex_Negative', 'Corr_DJIA_7 Corr_DJIA_28',\n",
    "#        'Corr_DJIA_7 Corr_Gold_7', 'Corr_DJIA_7 Corr_Gold_14',\n",
    "#        'Corr_DJIA_7 Corr_Gold_28', 'Corr_DJIA_21 Corr_DJIA_28',\n",
    "#        'Corr_DJIA_21 Corr_NASDAQ_28', 'Corr_Gold_7 Corr_Gold_14']\n",
    "\n",
    "X_selected = X_poly[selected_features]\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_selected)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameter tuning with GridSearchCV\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'max_features': ['sqrt', 'log2', None],\n",
    "#     'max_depth': [4, 6, 8, 10, None],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4]\n",
    "# }\n",
    "# grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# best_params = grid_search.best_params_\n",
    "best_params = {}\n",
    "\n",
    "# Train with best parameters\n",
    "rf_best = RandomForestClassifier(**best_params, random_state=42)\n",
    "rf_best.fit(X_train, y_train)\n",
    "\n",
    "# Initialize the models\n",
    "log_clf = LogisticRegression(random_state=42)\n",
    "svm_clf = SVC(probability=True, random_state=42)\n",
    "rf_clf = RandomForestClassifier(**best_params, random_state=42)\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('svc', svm_clf), ('rf', rf_clf)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Train the voting classifier\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5846153846153846\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.55      0.54        88\n",
      "           1       0.62      0.62      0.62       107\n",
      "\n",
      "    accuracy                           0.58       195\n",
      "   macro avg       0.58      0.58      0.58       195\n",
      "weighted avg       0.59      0.58      0.58       195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict and evaluate the model\n",
    "y_pred = rf_best.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5538461538461539\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.56      0.53        88\n",
      "           1       0.60      0.55      0.58       107\n",
      "\n",
      "    accuracy                           0.55       195\n",
      "   macro avg       0.55      0.55      0.55       195\n",
      "weighted avg       0.56      0.55      0.55       195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "m = XGBClassifier()\n",
    "m.fit(X_train, y_train)\n",
    "\n",
    "y_pred = m.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6051282051282051\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.53      0.55        88\n",
      "           1       0.63      0.66      0.65       107\n",
      "\n",
      "    accuracy                           0.61       195\n",
      "   macro avg       0.60      0.60      0.60       195\n",
      "weighted avg       0.60      0.61      0.60       195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRFClassifier\n",
    "\n",
    "m = XGBRFClassifier()\n",
    "m.fit(X_train, y_train)\n",
    "\n",
    "y_pred = m.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 110592 candidates, totalling 552960 fits\n"
     ]
    }
   ],
   "source": [
    "# Initialize the XGBoost classifier\n",
    "xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9, 1.0],\n",
    "    'reg_alpha': [0, 0.01, 0.1, 1],\n",
    "    'reg_lambda': [0, 0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "# Perform Grid Search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=xgb_clf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best accuracy found: \", grid_search.best_score_)\n",
    "\n",
    "# Train the best model\n",
    "best_xgb = grid_search.best_estimator_\n",
    "best_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5794 - loss: 0.7543 - val_accuracy: 0.5192 - val_loss: 0.7105\n",
      "Epoch 2/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5130 - loss: 0.7686 - val_accuracy: 0.5449 - val_loss: 0.6940\n",
      "Epoch 3/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5343 - loss: 0.7248 - val_accuracy: 0.5769 - val_loss: 0.6930\n",
      "Epoch 4/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.5335 - loss: 0.7208 - val_accuracy: 0.5128 - val_loss: 0.6893\n",
      "Epoch 5/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5341 - loss: 0.7029 - val_accuracy: 0.5449 - val_loss: 0.6885\n",
      "Epoch 6/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.4995 - loss: 0.7368 - val_accuracy: 0.5769 - val_loss: 0.6891\n",
      "Epoch 7/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5036 - loss: 0.7072 - val_accuracy: 0.5833 - val_loss: 0.6900\n",
      "Epoch 8/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5214 - loss: 0.7155 - val_accuracy: 0.5833 - val_loss: 0.6919\n",
      "Epoch 9/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5509 - loss: 0.7032 - val_accuracy: 0.5641 - val_loss: 0.6922\n",
      "Epoch 10/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5096 - loss: 0.6900 - val_accuracy: 0.5577 - val_loss: 0.6921\n",
      "Epoch 11/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.5245 - loss: 0.6932 - val_accuracy: 0.5641 - val_loss: 0.6918\n",
      "Epoch 12/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5243 - loss: 0.7027 - val_accuracy: 0.5577 - val_loss: 0.6916\n",
      "Epoch 13/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.5214 - loss: 0.7090 - val_accuracy: 0.5577 - val_loss: 0.6918\n",
      "Epoch 14/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.5457 - loss: 0.6851 - val_accuracy: 0.5577 - val_loss: 0.6914\n",
      "Epoch 15/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.5075 - loss: 0.6971 - val_accuracy: 0.5449 - val_loss: 0.6907\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.5596 - loss: 0.6867\n",
      "Test Accuracy: 0.5333\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=16, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kunaljain/opt/anaconda3/envs/gizaagents/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5394 - loss: 0.6925 - val_accuracy: 0.4423 - val_loss: 0.6949\n",
      "Epoch 2/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5344 - loss: 0.6911 - val_accuracy: 0.4487 - val_loss: 0.6955\n",
      "Epoch 3/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5447 - loss: 0.6898 - val_accuracy: 0.4487 - val_loss: 0.6968\n",
      "Epoch 4/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.5410 - loss: 0.6851 - val_accuracy: 0.4551 - val_loss: 0.6962\n",
      "Epoch 5/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5248 - loss: 0.6907 - val_accuracy: 0.5128 - val_loss: 0.6937\n",
      "Epoch 6/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.5179 - loss: 0.6916 - val_accuracy: 0.5256 - val_loss: 0.6910\n",
      "Epoch 7/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - accuracy: 0.5466 - loss: 0.6904 - val_accuracy: 0.4551 - val_loss: 0.6969\n",
      "Epoch 8/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.5364 - loss: 0.6868 - val_accuracy: 0.4872 - val_loss: 0.6948\n",
      "Epoch 9/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5388 - loss: 0.6922 - val_accuracy: 0.5128 - val_loss: 0.6929\n",
      "Epoch 10/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.4741 - loss: 0.6975 - val_accuracy: 0.4487 - val_loss: 0.6981\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.5669 - loss: 0.6862\n",
      "Test Accuracy: 0.5487\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv1D, GlobalAveragePooling1D, Reshape\n",
    "\n",
    "# Reshape data for 1D CNN\n",
    "X_train_cnn = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_cnn = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Build the model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train_cnn.shape[1], 1)))\n",
    "cnn_model.add(GlobalAveragePooling1D())\n",
    "cnn_model.add(Dense(32, activation='relu'))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history_cnn = cnn_model.fit(X_train_cnn, y_train, epochs=100, batch_size=16, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = cnn_model.evaluate(X_test_cnn, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kunaljain/opt/anaconda3/envs/gizaagents/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4983 - loss: 1.2519 - val_accuracy: 0.5705 - val_loss: 0.6863\n",
      "Epoch 2/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5473 - loss: 1.0972 - val_accuracy: 0.5449 - val_loss: 0.6998\n",
      "Epoch 3/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4985 - loss: 1.1533 - val_accuracy: 0.4551 - val_loss: 0.6888\n",
      "Epoch 4/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4711 - loss: 0.9777 - val_accuracy: 0.5385 - val_loss: 0.6769\n",
      "Epoch 5/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4948 - loss: 0.8936 - val_accuracy: 0.5256 - val_loss: 0.6815\n",
      "Epoch 6/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5276 - loss: 0.8326 - val_accuracy: 0.5192 - val_loss: 0.6902\n",
      "Epoch 7/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5797 - loss: 0.7485 - val_accuracy: 0.5577 - val_loss: 0.6919\n",
      "Epoch 8/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5207 - loss: 0.7825 - val_accuracy: 0.5128 - val_loss: 0.6902\n",
      "Epoch 9/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4970 - loss: 0.8152 - val_accuracy: 0.5000 - val_loss: 0.7006\n",
      "Epoch 10/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5205 - loss: 0.7725 - val_accuracy: 0.4872 - val_loss: 0.6927\n",
      "Epoch 11/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4948 - loss: 0.7707 - val_accuracy: 0.5256 - val_loss: 0.6895\n",
      "Epoch 12/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5306 - loss: 0.7428 - val_accuracy: 0.4808 - val_loss: 0.6919\n",
      "Epoch 13/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4896 - loss: 0.7663 - val_accuracy: 0.4359 - val_loss: 0.6924\n",
      "Epoch 14/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5533 - loss: 0.7167 - val_accuracy: 0.4872 - val_loss: 0.6928\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.5782 - loss: 0.6739\n",
      "Test Accuracy: 0.5487\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_poly)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=16, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(780, 1484)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poly selected features\n",
    "['OBV VWAP', 'VWAP Keltner_Lower', 'RSI_7 Vortex_Negative',\n",
    "       'Williams_%R RVI', 'Williams_%R Corr_DJIA_21', 'CMF Corr_Gold_14',\n",
    "       'Vortex_Positive Vortex_Negative', 'Corr_DJIA_7 Corr_Gold_7',\n",
    "       'Corr_DJIA_7 Corr_Gold_14', 'Corr_DJIA_21 Corr_DJIA_28']\n",
    "\n",
    "['Stochastic Vortex_Negative', 'OBV VWAP', 'MACD_Hist ROC',\n",
    "       'VWAP Keltner_Lower', 'VWAP Vortex_Negative', 'RSI_7 Vortex_Negative',\n",
    "       'RSI_21 Vortex_Negative', 'CCI RVI', 'Williams_%R Kijun_Sen',\n",
    "       'Williams_%R RVI', 'Williams_%R Corr_DJIA_21', 'CMF Corr_Gold_14',\n",
    "       'Vortex_Positive Vortex_Negative', 'Corr_DJIA_7 Corr_DJIA_28',\n",
    "       'Corr_DJIA_7 Corr_Gold_7', 'Corr_DJIA_7 Corr_Gold_14',\n",
    "       'Corr_DJIA_7 Corr_Gold_28', 'Corr_DJIA_21 Corr_DJIA_28',\n",
    "       'Corr_DJIA_21 Corr_NASDAQ_28', 'Corr_Gold_7 Corr_Gold_14']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gizaagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
